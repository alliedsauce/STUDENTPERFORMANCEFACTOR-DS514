# üéì STUDENT PERFORMANCE FACTOR (Part 2)

## üñ•Ô∏è Machine Learning

### **üìä ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß**
  - ‚úÖ **Questions & Hypothesis**
  - ‚úÖ **Data Cleansing**
  - ‚úÖ **Exploratory Data Analysis (EDA)**
  - ‚úÖ **Findings and Insights**
  - ‚úÖ **Recommendation/Action and Impact**
  - ‚úÖ **Source** https://github.com/alliedsauce/STUDENTPERFORMANCEFACTOR-DS512

---

## **üéØ SMART Objectives**

‡∏¢‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥ (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏≠‡∏ö < 70) ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô 10% ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πã‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏≠‡∏ö ‚â• 70) ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏™‡∏¥‡πâ‡∏ô‡∏õ‡∏µ‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤ 2568
‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏ä‡∏±‡πâ‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡∏Ç‡∏≠‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏®‡∏∂‡∏Å‡∏©‡∏≤ ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ

---
## **üåê Modeling Methodology**
**üåê ‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏° SMART Objectives**
 1. ‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô 2 ‡∏Å‡∏•‡∏∏‡πà‡∏° ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 6,607 Records
    - ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥ (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏≠‡∏ö < 70) ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô 4,982 ‡∏Ñ‡∏ô
    - ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏≠‡∏ö ‚â• 70) ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô 1,625 ‡∏Ñ‡∏ô
 2. ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• Supervised Learning ‡πÅ‡∏ö‡∏ö Classification
    - Label: ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥ ‡πÅ‡∏•‡∏∞ ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á
 3. ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ
    - Logistic Regression

---

## **üåê Data Preprocessing**
 **1. Target variables & feature**
 
 **‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏° score_group ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡πÑ‡∏õ‡πÄ‡∏õ‡πá‡∏ô Target**
  ```python
  df['Score_Group'] = np.where(df['Exam_Score'] >= 70,'‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á', '‡∏ï‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥')
  y = df['Score_Group']
  ```
 **‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Feature**
   ```python
  feature_columns = [
    'Attendance',
    'Hours_Studied',
    'Previous_Scores',
    'Tutoring_Sessions',
    'Internet_Access',
    'Motivation_Level',
    'Family_Income',
    'Extracurricular_Activities',
    'Parental_Involvement'
  ]
  X = df[feature_columns]
  ```
 **2. Encoding**
  ```python
  #‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á (NaN) ‡∏ó‡∏±‡πâ‡∏á‡πÉ‡∏ô X ‡πÅ‡∏•‡∏∞ y
  print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô: {len(X)}")
  X = X.dropna()
  y = y.loc[X.index]
  print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏´‡∏•‡∏±‡∏á‡∏•‡∏ö‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á: {len(X)}")

  #‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö‡∏•‡∏≥‡∏î‡∏±‡∏ö (Ordinal Encoding) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö 3 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
  ordinal_cols = [
    'Parental_Involvement',
    'Family_Income',
    'Motivation_Level',
  ]
  categories = [
    ['Low', 'Medium', 'High'],
    ['Low', 'Medium', 'High'],
    ['Low', 'Medium', 'High'],
  ]
  encoder = OrdinalEncoder(categories=categories)
  #‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô String ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤ encoder
  X[ordinal_cols] = encoder.fit_transform(X[ordinal_cols].astype(str))

  #‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö Binary (Yes/No)
  binary_cols = ['Internet_Access','Extracurricular_Activities']
  X[binary_cols] = X[binary_cols].replace({'Yes': 1, 'No': 0})

  #‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
  numeric_cols = ['Attendance', 'Hours_Studied','Previous_Scores','Tutoring_Sessions']
  for col in numeric_cols:
    X[col] = pd.to_numeric(X[col], errors='coerce')
 ```

 **3. Train/Test Split**     
 ```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
print("‡∏Ç‡∏ô‡∏≤‡∏î‡∏ä‡∏∏‡∏î Train:", X_train.shape)
print("‡∏Ç‡∏ô‡∏≤‡∏î‡∏ä‡∏∏‡∏î Test :", X_test.shape)
```
**4. Scaling Strategies: Standard Scalar**
```python
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scale = scaler.fit_transform(X_train)
X_test_scale = scaler.transform(X_test)
```
**5. Model: Logistic Regression**
```python
from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression(max_iter=200)
logreg.fit(X_train_scale, y_train)

y_pred = logreg.predict(X_test_scale)
```
**6. Confusion Matrix**
```python
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt='d')
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()
```
//pic

**6. Classification Report**
```python
print(classification_report(y_test, y_pred))
```
---
