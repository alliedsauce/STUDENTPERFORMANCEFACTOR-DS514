# üéì STUDENT PERFORMANCE FACTOR (Part 2)

## üñ•Ô∏è Machine Learning

### **üìä ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß**
  - ‚úÖ **Questions & Hypothesis**
  - ‚úÖ **Data Cleansing**
  - ‚úÖ **Exploratory Data Analysis (EDA)**
  - ‚úÖ **Findings and Insights**
  - ‚úÖ **Recommendation/Action and Impact**
  - ‚úÖ **Source** https://github.com/alliedsauce/STUDENTPERFORMANCEFACTOR-DS512

---

## **üéØ SMART Objectives**

‡∏¢‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥ (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏≠‡∏ö < 70) ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô 10% ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πã‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏≠‡∏ö ‚â• 70) ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏™‡∏¥‡πâ‡∏ô‡∏õ‡∏µ‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤ 2568
‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏ä‡∏±‡πâ‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡∏Ç‡∏≠‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏®‡∏∂‡∏Å‡∏©‡∏≤ ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ

---
## **üåê Modeling Methodology**
**üì¶ ‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏° SMART Objectives**
 1. ‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô 2 ‡∏Å‡∏•‡∏∏‡πà‡∏° ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 6,607 Records
    - ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥ (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏≠‡∏ö < 70) ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô 4,982 ‡∏Ñ‡∏ô
    - ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏≠‡∏ö ‚â• 70) ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô 1,625 ‡∏Ñ‡∏ô
 2. ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• Supervised Learning ‡πÅ‡∏ö‡∏ö Classification
    - Label: ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥ ‡πÅ‡∏•‡∏∞ ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á
 3. ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ
    - Logistic Regression

---

## **üóÇÔ∏è Data Preprocessing**
 **1. üöÄ Target variables & feature**
 
 **Target: score_group**
  ```python
  df['Score_Group'] = np.where(df['Exam_Score'] >= 70,'‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á', '‡∏ï‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥')
  y = df['Score_Group']
  ```
 **Feature**
   ```python
  feature_columns = [
    'Attendance',
    'Hours_Studied',
    'Previous_Scores',
    'Tutoring_Sessions',
    'Internet_Access',
    'Motivation_Level',
    'Family_Income',
    'Extracurricular_Activities',
    'Parental_Involvement'
  ]
  X = df[feature_columns]
  ```

---

 **2. üßÆ Encoding**
  ```python
  #‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á (NaN) ‡∏ó‡∏±‡πâ‡∏á‡πÉ‡∏ô X ‡πÅ‡∏•‡∏∞ y
  print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô: {len(X)}")
  X = X.dropna()
  y = y.loc[X.index]
  print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏´‡∏•‡∏±‡∏á‡∏•‡∏ö‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á: {len(X)}")

  #‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö‡∏•‡∏≥‡∏î‡∏±‡∏ö (Ordinal Encoding) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö 3 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
  ordinal_cols = [
    'Parental_Involvement',
    'Family_Income',
    'Motivation_Level',
  ]
  categories = [
    ['Low', 'Medium', 'High'],
    ['Low', 'Medium', 'High'],
    ['Low', 'Medium', 'High'],
  ]
  encoder = OrdinalEncoder(categories=categories)
  #‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô String ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤ encoder
  X[ordinal_cols] = encoder.fit_transform(X[ordinal_cols].astype(str))

  #‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö Binary (Yes/No)
  binary_cols = ['Internet_Access','Extracurricular_Activities']
  X[binary_cols] = X[binary_cols].replace({'Yes': 1, 'No': 0})

  #‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
  numeric_cols = ['Attendance', 'Hours_Studied','Previous_Scores','Tutoring_Sessions']
  for col in numeric_cols:
    X[col] = pd.to_numeric(X[col], errors='coerce')
 ```

---

 **3. ‚úÇÔ∏è Train/Test Split**     
 ```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
print("‡∏Ç‡∏ô‡∏≤‡∏î‡∏ä‡∏∏‡∏î Train:", X_train.shape)
print("‡∏Ç‡∏ô‡∏≤‡∏î‡∏ä‡∏∏‡∏î Test :", X_test.shape)
```

---

**4. ‚öñÔ∏è Scaling Strategies: Standard Scalar**
```python
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scale = scaler.fit_transform(X_train)
X_test_scale = scaler.transform(X_test)
```

---

**5. ü§ñ Model: Logistic Regression**
```python
from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression(max_iter=200)
logreg.fit(X_train_scale, y_train)

y_pred = logreg.predict(X_test_scale)
```

---

**6. üî¢Confusion Matrix**
```python
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt='d')
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()
```
![Confusion Matrix](Material/CM.png)

Label 0 (Negative Class) ‚áí ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á

Label 1 (Positive Class) ‚áí  ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥

**‚úîÔ∏è‚ùåTrue Negative (TN)** = 244 (‡∏ö‡∏ô‡∏ã‡πâ‡∏≤‡∏¢)

‡πÅ‡∏õ‡∏•‡∏ß‡πà‡∏≤: ‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á (‡πåN) ‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á

**‚úîÔ∏è‚úîÔ∏èTrue Positive (TP)** = 960 (‡∏•‡πà‡∏≤‡∏á‡∏Ç‡∏ß‡∏≤)

‡πÅ‡∏õ‡∏•‡∏ß‡πà‡∏≤: ‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥ (‡πåP) ‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á

**‚ùå‚ùåFalse Negative (FN)** = 37 (‡∏•‡πà‡∏≤‡∏á‡∏ã‡πâ‡∏≤‡∏¢)

‡πÅ‡∏õ‡∏•‡∏ß‡πà‡∏≤: ‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á (‡πåN) ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î

**‚ùå‚úîÔ∏èFalse Positive (FP)** = 81 (‡∏ö‡∏ô‡∏Ç‡∏ß‡∏≤)

‡πÅ‡∏õ‡∏•‡∏ß‡πà‡∏≤: ‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥ (‡πåP) ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î

---

**7. üìä Classification Report**
```python
print(classification_report(y_test, y_pred))
```

## Classification Report

|    | Precision | Recall | F1-Score | Support |
|--------------|-----------|--------|----------|---------|
| ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á     | 0.87      | 0.75   | 0.81     | 325     |
| ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥     | 0.92      | 0.96   | 0.94     | 997     |
| Accuracy     |           |        | 0.91     | 1322    |
| Macro Avg    | 0.90      | 0.86   | 0.87     | 1322    |
| Weighted Avg | 0.91      | 0.91   | 0.91     | 1322    |

Support: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏•‡∏≤‡∏™
‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á = 325
‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥ = 997
‡∏£‡∏ß‡∏° = 1322

Accuracy ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ñ‡∏π‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
0.91 ‚Üí ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á 91% ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

Precision
‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á (TN) = 0.87 ‚Üí ‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ß‡πà‡∏≤ ‚Äú‡∏™‡∏π‡∏á‚Äù ‡∏°‡∏µ 87% ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á
‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥ (TP) = 0.92 ‚Üí ‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ß‡πà‡∏≤ ‚Äú‡∏ï‡πà‡∏≥‚Äù ‡∏°‡∏µ 92% ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á

Recall 
‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á = 0.75 ‚Üí ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ 75% ‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏π‡∏á‡∏à‡∏£‡∏¥‡∏á
‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥ = 0.96 ‚Üí ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ 96% ‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡πà‡∏≥‡∏à‡∏£‡∏¥‡∏á

‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å‡∏ï‡∏≤‡∏£‡∏≤‡∏á
‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏î‡∏µ‡∏°‡∏≤‡∏Å‡∏Å‡∏±‡∏ö ‚Äú‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥‚Äù (Recall = 0.96, F1 = 0.94)
‚Äú‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‚Äù ‡∏°‡∏µ Precision ‡∏î‡∏µ (0.87) ‡πÅ‡∏ï‡πà Recall ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ (0.75) ‚Üí ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏•‡∏≤‡∏î‡∏ö‡∏≤‡∏á‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏π‡∏á
Accuracy ‡∏£‡∏ß‡∏° = 91% ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏î‡∏µ


---
