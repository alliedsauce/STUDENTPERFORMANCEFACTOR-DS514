# üéì STUDENT PERFORMANCE FACTOR (Part 2)

## üñ•Ô∏è Machine Learning

### **üìä ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß**
  - ‚úÖ **Questions & Hypothesis**
  - ‚úÖ **Data Cleansing**
  - ‚úÖ **Exploratory Data Analysis (EDA)**
  - ‚úÖ **Findings and Insights**
  - ‚úÖ **Recommendation/Action and Impact**
  - ‚úÖ **Source** https://github.com/alliedsauce/STUDENTPERFORMANCEFACTOR-DS512

---

## **üéØ SMART Objectives**

‡∏¢‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥ (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏≠‡∏ö < 70) ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô 10% ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πã‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏≠‡∏ö ‚â• 70) ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏™‡∏¥‡πâ‡∏ô‡∏õ‡∏µ‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤ 2568
‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏ä‡∏±‡πâ‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡∏Ç‡∏≠‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏®‡∏∂‡∏Å‡∏©‡∏≤ ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ

---
## **üåê Modeling Methodology**
### **üì¶ Data Grouping**
 ‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô 2 ‡∏Å‡∏•‡∏∏‡πà‡∏° ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 6,607 Records
 - **‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á (0):** ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏≠‡∏ö ‚â• 70 ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô 1,625 ‡∏Ñ‡∏ô
 - **‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥ (1):** ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏≠‡∏ö < 70 ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô 4,982 ‡∏Ñ‡∏ô

### **üß† Model Type**
 - **Supervised Learning** ‡πÅ‡∏ö‡∏ö Classification
 - **Label:** ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á (0) ‡πÅ‡∏•‡∏∞‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥ (1)
 - **Features:** Attendance, Hours_Studied, Previous_Scores, Tutoring_Sessions, Internet_Access, Motivation_Level, Family_Income, Extracurricular_Activities, Parental_Involvement

### **üß© Chosen Model**
 - **Logistic Regression:** ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö Binary Classification ‡πÅ‡∏•‡∏∞‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏á‡πà‡∏≤‡∏¢

---

## **üóÇÔ∏è Data Preprocessing**
 
 **üöÄ Target: score_group**
  ```python
  df['Score_Group'] = np.where(df['Exam_Score'] >= 70,'‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á', '‡∏ï‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥')
  y = df['Score_Group']
  ```
 **üî† Feature**
   ```python
  feature_columns = [
    'Attendance',
    'Hours_Studied',
    'Previous_Scores',
    'Tutoring_Sessions',
    'Internet_Access',
    'Motivation_Level',
    'Family_Income',
    'Extracurricular_Activities',
    'Parental_Involvement'  ]
    X = df[feature_columns]
  ```

---

 **üßÆ Encoding**
  ```python
  #1. ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á (NaN) ‡∏ó‡∏±‡πâ‡∏á‡πÉ‡∏ô X ‡πÅ‡∏•‡∏∞ y
  X = X.dropna()
  y = y.loc[X.index]

  #2. ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö‡∏•‡∏≥‡∏î‡∏±‡∏ö (Ordinal Encoding) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö 3 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
  ordinal_cols = ['Parental_Involvement', 'Family_Income', 'Motivation_Level']
  categories = [
    ['Low', 'Medium', 'High'],
    ['Low', 'Medium', 'High'],
    ['Low', 'Medium', 'High'],]
  encoder = OrdinalEncoder(categories=categories)
  #‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô String ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤ encoder
  X[ordinal_cols] = encoder.fit_transform(X[ordinal_cols].astype(str))

  #3. ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö Binary (Yes/No)
  binary_cols = ['Internet_Access','Extracurricular_Activities']
  X[binary_cols] = X[binary_cols].replace({'Yes': 1, 'No': 0})

  #4. ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
  numeric_cols = ['Attendance', 'Hours_Studied','Previous_Scores','Tutoring_Sessions']
  for col in numeric_cols:
    X[col] = pd.to_numeric(X[col], errors='coerce')
 ```

---

 **‚úÇÔ∏è Train/Test Split**     
 ```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
```
- ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ä‡∏∏‡∏î Train: (5285, 9)
- ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ä‡∏∏‡∏î Test : (1322, 9)

---

**‚öñÔ∏è Scaling Strategies: StandardScaler**
```python
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scale = scaler.fit_transform(X_train)
X_test_scale = scaler.transform(X_test)
```

---

**ü§ñ Model: Logistic Regression**
```python
from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression(max_iter=200)
logreg.fit(X_train_scale, y_train)

y_pred = logreg.predict(X_test_scale)
```

---

**üî¢Confusion Matrix**
```python
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt='d')
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()
```
![Confusion Matrix](Material/CM.png)

Label 0 (Negative Class) ‚áí ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á

Label 1 (Positive Class) ‚áí  ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥

**‚úîÔ∏è‚ûïTrue Positive (TP)** = 960 (‡∏•‡πà‡∏≤‡∏á‡∏Ç‡∏ß‡∏≤)
- ‡πÅ‡∏õ‡∏•‡∏ß‡πà‡∏≤: ‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥ (‡πåP) ‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á

**‚úîÔ∏è‚ûñTrue Negative (TN)** = 244 (‡∏ö‡∏ô‡∏ã‡πâ‡∏≤‡∏¢)
- ‡πÅ‡∏õ‡∏•‡∏ß‡πà‡∏≤: ‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á (‡πåN) ‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á

**‚ùå‚ûïFalse Positive (FP)** = 81 (‡∏ö‡∏ô‡∏Ç‡∏ß‡∏≤)
- ‡πÅ‡∏õ‡∏•‡∏ß‡πà‡∏≤: ‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥ (‡πåP) ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î

**‚ùå‚ûñFalse Negative (FN)** = 37 (‡∏•‡πà‡∏≤‡∏á‡∏ã‡πâ‡∏≤‡∏¢)
- ‡πÅ‡∏õ‡∏•‡∏ß‡πà‡∏≤: ‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á (‡πåN) ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î

---

**üìä Classification Report**
```python
print(classification_report(y_test, y_pred))
```
|    | Precision | Recall | F1-Score | Support |
|--------------|-----------|--------|----------|---------|
| ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á     | 0.87      | 0.75   | 0.81     | 325     |
| ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥     | 0.92      | 0.96   | 0.94     | 997     |
| Accuracy     |           |        | **0.91**     | 1322    |
| Macro Avg    | 0.90      | 0.86   | 0.87     | 1322    |
| Weighted Avg | 0.91      | 0.91   | 0.91     | 1322    |

**üíæ Support:** ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏•‡∏≤‡∏™
- ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á (0) = 325
- ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥ (1) = 997
- ‡∏£‡∏ß‡∏° = 1322

**üî• Accuracy:** ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ñ‡∏π‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
- 0.91 ‚Üí ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á 91% ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (1322 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á)

**‚úÖ Precision** (‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏•‡∏≤‡∏™‡∏ô‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á):
- ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á (0) = 0.87 ‚Üí ‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ß‡πà‡∏≤ **‚Äú‡∏™‡∏π‡∏á‚Äù** ‡∏°‡∏µ 87% ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á
- ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥ (1) = 0.92 ‚Üí ‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ß‡πà‡∏≤ **‚Äú‡∏ï‡πà‡∏≥‚Äù** ‡∏°‡∏µ 92% ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á

**üîç Recall** 
- ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á (0) 0.75 ‚Üí ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ 75% ‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏π‡∏á‡∏à‡∏£‡∏¥‡∏á
- ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥ (1) 0.96 ‚Üí ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ 96% ‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡πà‡∏≥‡∏à‡∏£‡∏¥‡∏á

**üåü ‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å‡∏ï‡∏≤‡∏£‡∏≤‡∏á**
- ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏î‡∏µ‡∏°‡∏≤‡∏Å‡∏Å‡∏±‡∏ö ‚Äú‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥‚Äù (Recall = 0.96, F1 = 0.94)
- **‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á** ‡∏°‡∏µ Precision ‡∏î‡∏µ (0.87) ‡πÅ‡∏ï‡πà Recall ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ (0.75) ‚Üí ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏•‡∏≤‡∏î‡∏ö‡∏≤‡∏á‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏π‡∏á
- Accuracy ‡∏£‡∏ß‡∏° = 91% ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏î‡∏µ
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏°‡πà‡∏™‡∏°‡∏î‡∏∏‡∏•‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏•‡∏≤‡∏™ (997 vs 325)

üôèüôèüôè
---
